{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "FOR THE JSON  DATA: 20230916_01-16-54-377_1018_userinfo.json. \n",
    "\n",
    "{\"CGUID\":\"1018\",\"Date\":\"20230916_01:16:54:377\",\n",
    "\n",
    "\"ShotResult\":[\n",
    "\n",
    "    7.6970219612121582, 25.65673828125, -----> Head speed (m/s)  is sum of first and second column = 7.697021961212158 + 25.65673828125\n",
    "\n",
    "    -0.608303964138031, ------> Face angle (degree)\n",
    "\n",
    "    8.4586247339757392E-07, -----> Attack angle (degree)\n",
    "\n",
    "    -2.7872023582458496, -----> Swing path (degree)\n",
    "\n",
    "    2.0588235855102539, ------> Swing tempo (ratio)\n",
    "\n",
    "    97.855049133300781,  -----> Swing backtop (degree) \n",
    "\n",
    "    0.34999999403953552, -----> Back swing time (second) \n",
    "\n",
    "    0.17000000178813934, -----> Down swing time (second)\n",
    "\n",
    "    1.0 -----> Hand (1 = RIGHT, 2 = LEFT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# File directories \n",
    "input_directory = r'C:\\Users\\james\\Desktop\\2023-2\\Raw\\logRaws'\n",
    "output_directory = r'C:\\Users\\James\\Desktop\\2023-2\\Raw\\userInfo'\n",
    "\n",
    "# Preprocess data for a single file\n",
    "def preprocess_single_file(input_file_path, output_file_path):\n",
    "\n",
    "    # Load CSV data -> filter rows where Swing Stage is not 0 -> extract swing_stage + 3 accel + 3 gyro values\n",
    "    input_data = pd.read_csv(input_file_path)\n",
    "    input_data = input_data[input_data.iloc[:, 3] != 0]\n",
    "    input_data = input_data.iloc[:, [3, 19, 20, 21, 25, 26, 27]]\n",
    "    # print(input_data.shape)\n",
    "    # input_data.columns = ['swing_stage', 'accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']\n",
    "\n",
    "\n",
    "    # Pad remaining values with zeros -> return np.array \n",
    "    target_shape = (999,7)\n",
    "    input_values = input_data.values\n",
    "    pad_rows = max(0, target_shape[0] - input_values.shape[0])\n",
    "    pad_cols = max(0, target_shape[1] - input_values.shape[1])\n",
    "    X = np.pad(input_values, ((0, pad_rows), (0, pad_cols)), mode='constant')\n",
    "    # print(X)\n",
    "\n",
    "    # Load JSON data -> If output is not available, skip\n",
    "    with open(output_file_path, 'r') as json_file:\n",
    "        try:\n",
    "            output_data = json.load(json_file)\n",
    "            output_data_df = pd.DataFrame(output_data['ShotResult'])\n",
    "            output_data_df = pd.DataFrame.transpose(output_data_df)\n",
    "\n",
    "            columns_to_remove = [5,7,8,9]\n",
    "            output_data_df = output_data_df.drop(columns=columns_to_remove)\n",
    "            # output_data_df.columns = ['swingspeed1', 'swingspeed2', 'faceangle', 'attackangle', 'swingpath', 'swingbacktop']\n",
    "            # print(output_data_df.shape)\n",
    "            Y = np.array(output_data_df)\n",
    "            # print(Y)\n",
    "        except KeyError as e:\n",
    "            return None, None\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def preprocess_all_files():\n",
    "\n",
    "    X_all_data = []\n",
    "    Y_all_data = []\n",
    "\n",
    "    # Iterate through all files\n",
    "    for input_file in os.listdir(input_directory):\n",
    "\n",
    "        # Construct the output file path based on the common prefix\n",
    "        common_prefix = '_'.join(input_file.split('_')[:-1]) + '_'\n",
    "        output_file = common_prefix + 'userinfo.json'\n",
    "        output_file_path = os.path.join(output_directory, output_file)\n",
    "\n",
    "        # Construct the input file path\n",
    "        input_file_path = os.path.join(input_directory, input_file)\n",
    "\n",
    "        # Preprocess the data for the current file\n",
    "        X, Y = preprocess_single_file(input_file_path, output_file_path)\n",
    "    \n",
    "        # Append the preprocessed data to the list if both values exist\n",
    "        if X is not None and Y is not None:\n",
    "            X_all_data.append(X)\n",
    "            Y_all_data.append(Y)\n",
    "\n",
    "\n",
    "    return np.array(X_all_data), np.array(Y_all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def percentage_difference_loss(y_true, y_pred):\n",
    "    # Calculate percentage difference\n",
    "    percentage_diff = tf.abs((y_true - y_pred) / tf.maximum(tf.abs(y_true), tf.keras.backend.epsilon()))\n",
    "    \n",
    "    # Take the mean across all elements in the batch\n",
    "    mean_percentage_diff = tf.reduce_mean(percentage_diff)\n",
    "    \n",
    "    return mean_percentage_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(3823, 999, 7)\n",
      "<class 'numpy.ndarray'>\n",
      "(3823, 1, 6)\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 999, 64)           18432     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 999, 64)           0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51846 (202.52 KB)\n",
      "Trainable params: 51846 (202.52 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000213909862A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000213909862A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000213909862A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "96/96 [==============================] - 74s 712ms/step - loss: 2.2003\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 76s 791ms/step - loss: 1.2566\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 47s 490ms/step - loss: 1.1939\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 35s 368ms/step - loss: 0.7984\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 34s 354ms/step - loss: 0.7565\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 34s 352ms/step - loss: 0.6179\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 34s 355ms/step - loss: 0.5230\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 34s 357ms/step - loss: 0.5018\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 35s 360ms/step - loss: 0.4878\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 36s 372ms/step - loss: 0.3836\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 36s 373ms/step - loss: 0.3564\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 34s 356ms/step - loss: 0.4009\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 35s 361ms/step - loss: 0.3404\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 56s 584ms/step - loss: 0.2823\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 42s 438ms/step - loss: 0.2372\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 35s 364ms/step - loss: 0.2258\n",
      "Epoch 17/50\n",
      "96/96 [==============================] - 35s 365ms/step - loss: 0.2000\n",
      "Epoch 18/50\n",
      "96/96 [==============================] - 35s 364ms/step - loss: 0.2032\n",
      "Epoch 19/50\n",
      "96/96 [==============================] - 35s 362ms/step - loss: 0.1916\n",
      "Epoch 20/50\n",
      "96/96 [==============================] - 35s 361ms/step - loss: 0.1980\n",
      "Epoch 21/50\n",
      "96/96 [==============================] - 35s 362ms/step - loss: 0.1576\n",
      "Epoch 22/50\n",
      "96/96 [==============================] - 35s 365ms/step - loss: 0.1838\n",
      "Epoch 23/50\n",
      "96/96 [==============================] - 35s 362ms/step - loss: 0.1779\n",
      "Epoch 24/50\n",
      "96/96 [==============================] - 35s 363ms/step - loss: 0.1445\n",
      "Epoch 25/50\n",
      "96/96 [==============================] - 35s 363ms/step - loss: 0.1708\n",
      "Epoch 26/50\n",
      "96/96 [==============================] - 35s 362ms/step - loss: 0.1056\n",
      "Epoch 27/50\n",
      "96/96 [==============================] - 35s 364ms/step - loss: 0.1337\n",
      "Epoch 28/50\n",
      "96/96 [==============================] - 35s 365ms/step - loss: 0.0921\n",
      "Epoch 29/50\n",
      "96/96 [==============================] - 35s 363ms/step - loss: 0.1357\n",
      "Epoch 30/50\n",
      "96/96 [==============================] - 35s 361ms/step - loss: 0.0980\n",
      "Epoch 31/50\n",
      "96/96 [==============================] - 35s 361ms/step - loss: 0.0986\n",
      "Epoch 32/50\n",
      "96/96 [==============================] - 40s 421ms/step - loss: 0.0788\n",
      "Epoch 33/50\n",
      "96/96 [==============================] - 47s 485ms/step - loss: 0.1018\n",
      "Epoch 34/50\n",
      "96/96 [==============================] - 47s 492ms/step - loss: 0.0707\n",
      "Epoch 35/50\n",
      "96/96 [==============================] - 47s 494ms/step - loss: 0.0823\n",
      "Epoch 36/50\n",
      "96/96 [==============================] - 47s 494ms/step - loss: 0.0854\n",
      "Epoch 37/50\n",
      "96/96 [==============================] - 47s 493ms/step - loss: 0.0671\n",
      "Epoch 38/50\n",
      "96/96 [==============================] - 46s 481ms/step - loss: 0.0667\n",
      "Epoch 39/50\n",
      "96/96 [==============================] - 48s 495ms/step - loss: 0.0752\n",
      "Epoch 40/50\n",
      "96/96 [==============================] - 47s 492ms/step - loss: 0.1039\n",
      "Epoch 41/50\n",
      "96/96 [==============================] - 47s 490ms/step - loss: 0.1177\n",
      "Epoch 42/50\n",
      "96/96 [==============================] - 48s 503ms/step - loss: 0.0654\n",
      "Epoch 43/50\n",
      "96/96 [==============================] - 47s 492ms/step - loss: 0.0704\n",
      "Epoch 44/50\n",
      "96/96 [==============================] - 44s 460ms/step - loss: 0.0709\n",
      "Epoch 45/50\n",
      "96/96 [==============================] - 35s 367ms/step - loss: 0.0615\n",
      "Epoch 46/50\n",
      "96/96 [==============================] - 35s 365ms/step - loss: 0.0762\n",
      "Epoch 47/50\n",
      "96/96 [==============================] - 35s 367ms/step - loss: 0.0710\n",
      "Epoch 48/50\n",
      "96/96 [==============================] - 35s 368ms/step - loss: 0.0697\n",
      "Epoch 49/50\n",
      "96/96 [==============================] - 36s 375ms/step - loss: 0.0738\n",
      "Epoch 50/50\n",
      "96/96 [==============================] - 35s 365ms/step - loss: 0.0739\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021396BC8EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021396BC8EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021396BC8EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "24/24 [==============================] - 3s 111ms/step - loss: 0.1950\n",
      "0.19498607516288757\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\james\\Desktop\\2023-2\\RNN\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\james\\Desktop\\2023-2\\RNN\\assets\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "X_data, Y_data  = preprocess_all_files()\n",
    "\n",
    "# Check input and output shape\n",
    "print(type(X_data))\n",
    "print(X_data.shape)\n",
    "print(type(Y_data))\n",
    "print(Y_data.shape)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(999, 7), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6, activation='linear'))\n",
    "\n",
    "# Compile modle\n",
    "model.compile(optimizer='adam', loss=percentage_difference_loss)\n",
    "model.summary()\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=32) \n",
    "\n",
    "# Evaluate model\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print(score)\n",
    "\n",
    "tf.saved_model.save(model, r'C:\\Users\\james\\Desktop\\2023-2\\RNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "\n",
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.layers.LSTM(units=hp.Int('units', min_value=32, max_value=512, step=32),\n",
    "                                input_shape=(999, 7)))\n",
    "\n",
    "    model.add(keras.layers.Dense(units=6, activation='linear'))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss=percentage_difference_loss,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
