{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "FOR THE JSON  DATA: 20230916_01-16-54-377_1018_userinfo.json. \n",
    "\n",
    "{\"CGUID\":\"1018\",\"Date\":\"20230916_01:16:54:377\",\n",
    "\n",
    "\"ShotResult\":[\n",
    "\n",
    "    7.6970219612121582, 25.65673828125, -----> Head speed (m/s)  is sum of first and second column = 7.697021961212158 + 25.65673828125\n",
    "\n",
    "    -0.608303964138031, ------> Face angle (degree)\n",
    "\n",
    "    8.4586247339757392E-07, -----> Attack angle (degree)\n",
    "\n",
    "    -2.7872023582458496, -----> Swing path (degree)\n",
    "\n",
    "    2.0588235855102539, ------> Swing tempo (ratio)\n",
    "\n",
    "    97.855049133300781,  -----> Swing backtop (degree) \n",
    "\n",
    "    0.34999999403953552, -----> Back swing time (second) \n",
    "\n",
    "    0.17000000178813934, -----> Down swing time (second)\n",
    "\n",
    "    1.0 -----> Hand (1 = RIGHT, 2 = LEFT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# File directories \n",
    "input_directory = r'C:\\Users\\james\\Desktop\\2023-2\\Raw\\logRaws'\n",
    "output_directory = r'C:\\Users\\James\\Desktop\\2023-2\\Raw\\userInfo'\n",
    "\n",
    "\n",
    "# Preprocess data for a single file\n",
    "def preprocess_single_file(input_file_path, output_file_path):\n",
    "\n",
    "    # Load CSV data -> filter rows where Swing Stage is not 0 -> extract swing_stage + 3 accel + 3 gyro values\n",
    "    input_data = pd.read_csv(input_file_path)\n",
    "    input_data = input_data[input_data.iloc[:, 3] != 0]\n",
    "    input_data = input_data.iloc[:, [3, 19, 20, 21, 25, 26, 27]]\n",
    "    # print(input_data.shape)\n",
    "    # input_data.columns = ['swing_stage', 'accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']\n",
    "\n",
    "\n",
    "    # Pad remaining values with zeros -> return np.array \n",
    "    target_shape = (999,7)\n",
    "    input_values = input_data.values\n",
    "    pad_rows = max(0, target_shape[0] - input_values.shape[0])\n",
    "    pad_cols = max(0, target_shape[1] - input_values.shape[1])\n",
    "    X = np.pad(input_values, ((0, pad_rows), (0, pad_cols)), mode='constant')\n",
    "    # print(X)\n",
    "\n",
    "    # Load JSON data -> If output is not available, skip\n",
    "    with open(output_file_path, 'r') as json_file:\n",
    "        try:\n",
    "            output_data = json.load(json_file)\n",
    "            output_data_df = pd.DataFrame(output_data['ShotResult'])\n",
    "            output_data_df = pd.DataFrame.transpose(output_data_df)\n",
    "\n",
    "            columns_to_remove = [2,3,4,5,6,7,8,9]\n",
    "            output_data_df = output_data_df.drop(columns=columns_to_remove)\n",
    "            # output_data_df.columns = ['swingspeed1', 'swingspeed2', 'faceangle', 'attackangle', 'swingpath', 'swingbacktop']\n",
    "            # print(output_data_df.shape)\n",
    "            Y = np.array(output_data_df)\n",
    "            # print(Y)\n",
    "        except KeyError as e:\n",
    "            return None, None\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def preprocess_all_files():\n",
    "    \n",
    "    X_all_data = []\n",
    "    Y_all_data = []\n",
    "\n",
    "    # Iterate through all files\n",
    "    for input_file in os.listdir(input_directory):\n",
    "\n",
    "        # Construct the output file path based on the common prefix\n",
    "        common_prefix = '_'.join(input_file.split('_')[:-1]) + '_'\n",
    "        output_file = common_prefix + 'userinfo.json'\n",
    "        output_file_path = os.path.join(output_directory, output_file)\n",
    "\n",
    "        # Construct the input file path\n",
    "        input_file_path = os.path.join(input_directory, input_file)\n",
    "\n",
    "        # Preprocess the data for the current file\n",
    "        X, Y = preprocess_single_file(input_file_path, output_file_path)\n",
    "    \n",
    "        # Append the preprocessed data to the list if both values exist\n",
    "        if X is not None and Y is not None:\n",
    "            X_all_data.append(X)\n",
    "            Y_all_data.append(Y)\n",
    "\n",
    "    return np.array(X_all_data), np.array(Y_all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def percentage_difference_loss(y_true, y_pred):\n",
    "    # Calculate percentage difference\n",
    "    percentage_diff = tf.abs((y_true - y_pred) / tf.maximum(tf.abs(y_true), tf.keras.backend.epsilon()))\n",
    "    \n",
    "    # Take the mean across all elements in the batch\n",
    "    mean_percentage_diff = tf.reduce_mean(percentage_diff) * 100\n",
    "    \n",
    "    return mean_percentage_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(3823, 999, 7)\n",
      "<class 'numpy.ndarray'>\n",
      "(3823, 1, 2)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 999, 64)           18432     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 999, 64)           0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51586 (201.51 KB)\n",
      "Trainable params: 51586 (201.51 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002139ABCBD80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002139ABCBD80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002139ABCBD80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "48/48 [==============================] - 27s 506ms/step - loss: 83.2424 - mae: 10.8742\n",
      "Epoch 2/20\n",
      "48/48 [==============================] - 24s 499ms/step - loss: 77.8491 - mae: 10.6796\n",
      "Epoch 3/20\n",
      "48/48 [==============================] - 25s 514ms/step - loss: 77.7578 - mae: 10.6746\n",
      "Epoch 4/20\n",
      "48/48 [==============================] - 25s 519ms/step - loss: 77.3254 - mae: 10.6730\n",
      "Epoch 5/20\n",
      "48/48 [==============================] - 25s 514ms/step - loss: 77.5475 - mae: 10.6698\n",
      "Epoch 6/20\n",
      "48/48 [==============================] - 24s 495ms/step - loss: 77.2708 - mae: 10.6819\n",
      "Epoch 7/20\n",
      "48/48 [==============================] - 24s 502ms/step - loss: 77.4783 - mae: 10.6702\n",
      "Epoch 8/20\n",
      "48/48 [==============================] - 27s 551ms/step - loss: 77.4492 - mae: 10.6705\n",
      "Epoch 9/20\n",
      "48/48 [==============================] - 27s 563ms/step - loss: 77.1852 - mae: 10.6703\n",
      "Epoch 10/20\n",
      "48/48 [==============================] - 26s 551ms/step - loss: 77.2611 - mae: 10.6821\n",
      "Epoch 11/20\n",
      "48/48 [==============================] - 26s 536ms/step - loss: 77.2185 - mae: 10.6696\n",
      "Epoch 12/20\n",
      "48/48 [==============================] - 27s 556ms/step - loss: 77.2103 - mae: 10.6710\n",
      "Epoch 13/20\n",
      "48/48 [==============================] - 26s 541ms/step - loss: 77.2307 - mae: 10.6656\n",
      "Epoch 14/20\n",
      "48/48 [==============================] - 27s 563ms/step - loss: 77.2127 - mae: 10.6746\n",
      "Epoch 15/20\n",
      "48/48 [==============================] - 26s 548ms/step - loss: 77.1254 - mae: 10.6755\n",
      "Epoch 16/20\n",
      "48/48 [==============================] - 25s 515ms/step - loss: 77.0983 - mae: 10.6669\n",
      "Epoch 17/20\n",
      "48/48 [==============================] - 26s 547ms/step - loss: 77.1289 - mae: 10.6589\n",
      "Epoch 18/20\n",
      "48/48 [==============================] - 25s 529ms/step - loss: 77.2034 - mae: 10.6792\n",
      "Epoch 19/20\n",
      "48/48 [==============================] - 25s 518ms/step - loss: 77.1748 - mae: 10.6581\n",
      "Epoch 20/20\n",
      "48/48 [==============================] - 26s 543ms/step - loss: 77.1526 - mae: 10.6739\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002139ABF8040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002139ABF8040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002139ABF8040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "24/24 [==============================] - 3s 105ms/step - loss: 73.7383 - mae: 10.1977\n",
      "[73.73834228515625, 10.197670936584473]\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\james\\Desktop\\2023-2\\RNN\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\james\\Desktop\\2023-2\\RNN\\assets\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "X_data, Y_data  = preprocess_all_files()\n",
    "\n",
    "print(type(X_data))\n",
    "print(X_data.shape)\n",
    "print(type(Y_data))\n",
    "print(Y_data.shape)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(999, 7), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation='linear'))\n",
    "\n",
    "# Compile modle\n",
    "model.compile(optimizer='adam', loss=percentage_difference_loss, metrics=['mae'])\n",
    "model.summary()\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, Y_train, epochs=20, batch_size=64) \n",
    "\n",
    "# Evaluate model\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print(score)\n",
    "\n",
    "tf.saved_model.save(model, r'C:\\Users\\james\\Desktop\\2023-2\\RNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "\n",
    "def model_builder(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.layers.LSTM(units=hp.Int('units', min_value=32, max_value=512, step=32),\n",
    "                                input_shape=(999, 7)))\n",
    "\n",
    "    model.add(keras.layers.Dense(units=2, activation='linear'))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mae'])\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
