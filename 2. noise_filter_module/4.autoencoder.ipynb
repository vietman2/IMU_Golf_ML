{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define a CNN-based autoencoder\n",
    "def create_cnn_autoencoder():\n",
    "    input_layer = Input(shape=(1000, 6, 1))  # Adjust the input shape\n",
    "\n",
    "    # Encoder\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    # ... add more layers as needed\n",
    "\n",
    "    # Decoder\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    # ... add more layers as needed\n",
    "\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    autoencoder = Model(input_layer, decoded)\n",
    "    return autoencoder\n",
    "\n",
    "DIR = \"../data/Raw/logRaws/\"\n",
    "\n",
    "NUM_SAMPLES = 2662\n",
    "NUM_FEATURES = 6\n",
    "NUM_FRAMES = 1000\n",
    "\n",
    "file_names = os.listdir(DIR)\n",
    "input_array = np.empty((NUM_SAMPLES, NUM_FRAMES, NUM_FEATURES))\n",
    "\n",
    "# prepare data\n",
    "def read_files(DIR):\n",
    "    all_files = os.listdir(DIR)\n",
    "\n",
    "    input_data = np.empty((0, 6), float)\n",
    "\n",
    "    for file in all_files:\n",
    "        file_path = os.path.join(DIR, file)\n",
    "        df = pd.read_csv(file_path, usecols=[1, 19, 20, 21, 25, 26, 27], header=None)\n",
    "        if df.shape[0] < 999:\n",
    "            continue\n",
    "\n",
    "        df.columns = ['frame', 'accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']\n",
    "        df_input = df[['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']]\n",
    "        df_input = df_input.astype('float32')\n",
    "\n",
    "        input_data = np.append(input_data, df_input, axis=0)\n",
    "    input_data = input_data.reshape(NUM_SAMPLES, NUM_FRAMES, NUM_FEATURES)\n",
    "\n",
    "    return input_data\n",
    "\n",
    "input_data = read_files(DIR)\n",
    "\n",
    "print(input_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten data\n",
    "data_flattened = input_data.reshape(input_data.shape[0], -1)\n",
    "\n",
    "# split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(data_flattened, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 17:17:58.126810: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-22 17:17:58.392591: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "2023-11-22 17:17:58.767774: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51096000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 17:17:59.083590: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 51096000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/vietman2/Workspace/.venv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/vietman2/Workspace/.venv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/vietman2/Workspace/.venv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/vietman2/Workspace/.venv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/vietman2/Workspace/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/vietman2/Workspace/.venv/lib/python3.9/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 6), found shape=(None, 1000, 6)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/vietman2/Workspace/IMU_Golf_ML/2. noise_filter_module/4.autoencoder.ipynb Cell 3\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vietman2/Workspace/IMU_Golf_ML/2.%20noise_filter_module/4.autoencoder.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m autoencoder, encoder, decoder \u001b[39m=\u001b[39m create_autoencoder(input_dim, encoding_dim)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vietman2/Workspace/IMU_Golf_ML/2.%20noise_filter_module/4.autoencoder.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m autoencoder\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mAdam(lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m), loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean_squared_error\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vietman2/Workspace/IMU_Golf_ML/2.%20noise_filter_module/4.autoencoder.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m autoencoder\u001b[39m.\u001b[39;49mfit(X_train, X_train,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vietman2/Workspace/IMU_Golf_ML/2.%20noise_filter_module/4.autoencoder.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m                 epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vietman2/Workspace/IMU_Golf_ML/2.%20noise_filter_module/4.autoencoder.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m                 batch_size\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vietman2/Workspace/IMU_Golf_ML/2.%20noise_filter_module/4.autoencoder.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m                 shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vietman2/Workspace/IMU_Golf_ML/2.%20noise_filter_module/4.autoencoder.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m                 validation_data\u001b[39m=\u001b[39;49m(X_test, X_test))\n",
      "File \u001b[0;32m~/Workspace/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file3lzr8u_6.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/vietman2/Workspace/.venv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/vietman2/Workspace/.venv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/vietman2/Workspace/.venv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/vietman2/Workspace/.venv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/vietman2/Workspace/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/vietman2/Workspace/.venv/lib/python3.9/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 6), found shape=(None, 1000, 6)\n"
     ]
    }
   ],
   "source": [
    "# Create and compile the CNN autoencoder\n",
    "autoencoder = create_cnn_autoencoder()\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
